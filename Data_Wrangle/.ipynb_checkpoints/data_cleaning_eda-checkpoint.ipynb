{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176960c8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis for Data Cleaning\n",
    "\n",
    "Script Name: data_cleaning_eda.ipynb\n",
    "\n",
    "Author: Brian Cain\n",
    "\n",
    "\n",
    "The purpose of this jupyter notebook is to explore the joined data for characteristics of the data that need to be cleaned before advancing to the data analysis phase. Findings from this EDA will motivate data cleaning functions defined in the data_cleaning.py script. This jupyter notebook will also be fluid through time in that if data issues arise in the future I will come back to this notebook to further explore the data issues and cite any changes to be made to data_cleaning.py.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1660439",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import pandas for dataframe management/operations\n",
    "import pandas as pd\n",
    "\n",
    "##Import numpy \n",
    "import numpy as np\n",
    "\n",
    "##Import tabulate for organized table creation\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e17da09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>week_num</th>\n",
       "      <th>school</th>\n",
       "      <th>rush_td</th>\n",
       "      <th>pass_td</th>\n",
       "      <th>rush_attempt</th>\n",
       "      <th>yp_rush</th>\n",
       "      <th>rush_yards</th>\n",
       "      <th>yp_pass</th>\n",
       "      <th>completion_attempts</th>\n",
       "      <th>...</th>\n",
       "      <th>offensive_plays</th>\n",
       "      <th>offensive_drives</th>\n",
       "      <th>offensive_ppa</th>\n",
       "      <th>offensive_successRate</th>\n",
       "      <th>offensive_explosiveness</th>\n",
       "      <th>offensive_powerSuccess</th>\n",
       "      <th>offensive_stuffRate</th>\n",
       "      <th>offensive_lineYards</th>\n",
       "      <th>offensive_secondLevelYards</th>\n",
       "      <th>offensive_openFieldYards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400603830</td>\n",
       "      <td>1</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>5.4</td>\n",
       "      <td>222</td>\n",
       "      <td>10.1</td>\n",
       "      <td>31-38</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.489647</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>1.272267</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>3.360976</td>\n",
       "      <td>1.414634</td>\n",
       "      <td>1.121951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400603830</td>\n",
       "      <td>1</td>\n",
       "      <td>New Mexico State</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2.9</td>\n",
       "      <td>64</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15-29</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>1.332495</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400787302</td>\n",
       "      <td>1</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>5.4</td>\n",
       "      <td>205</td>\n",
       "      <td>11.4</td>\n",
       "      <td>20-25</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.474904</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1.228407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3.752778</td>\n",
       "      <td>1.638889</td>\n",
       "      <td>1.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400787302</td>\n",
       "      <td>1</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.6</td>\n",
       "      <td>100</td>\n",
       "      <td>6.2</td>\n",
       "      <td>36-48</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.094651</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.832628</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400763403</td>\n",
       "      <td>1</td>\n",
       "      <td>Texas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2.1</td>\n",
       "      <td>60</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8-23</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.101281</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>1.123873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>2.532000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gameId  week_num            school  rush_td  pass_td  rush_attempt  \\\n",
       "0  400603830         1           Florida        4        4            41   \n",
       "1  400603830         1  New Mexico State        1        1            22   \n",
       "2  400787302         1              Ohio        2        3            38   \n",
       "3  400787302         1             Idaho        2        1            28   \n",
       "4  400763403         1             Texas        0        0            29   \n",
       "\n",
       "   yp_rush  rush_yards  yp_pass completion_attempts  ...  offensive_plays  \\\n",
       "0      5.4         222     10.1               31-38  ...             81.0   \n",
       "1      2.9          64      4.7               15-29  ...             51.0   \n",
       "2      5.4         205     11.4               20-25  ...             64.0   \n",
       "3      3.6         100      6.2               36-48  ...             78.0   \n",
       "4      2.1          60      4.5                8-23  ...             53.0   \n",
       "\n",
       "   offensive_drives  offensive_ppa  offensive_successRate  \\\n",
       "0              13.0       0.489647               0.567901   \n",
       "1              13.0       0.000437               0.274510   \n",
       "2              10.0       0.474904               0.531250   \n",
       "3              12.0       0.094651               0.538462   \n",
       "4              12.0      -0.101281               0.264151   \n",
       "\n",
       "   offensive_explosiveness  offensive_powerSuccess  offensive_stuffRate  \\\n",
       "0                 1.272267                0.666667             0.146341   \n",
       "1                 1.332495                0.666667             0.250000   \n",
       "2                 1.228407                1.000000             0.111111   \n",
       "3                 0.832628                0.750000             0.080000   \n",
       "4                 1.123873                0.000000             0.120000   \n",
       "\n",
       "   offensive_lineYards offensive_secondLevelYards offensive_openFieldYards  \n",
       "0             3.360976                   1.414634                 1.121951  \n",
       "1             2.565000                   0.950000                 1.000000  \n",
       "2             3.752778                   1.638889                 1.388889  \n",
       "3             3.520000                   1.080000                 0.520000  \n",
       "4             2.532000                   0.720000                 0.040000  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Pull in the joined dataframe\n",
    "joinedDf = pd.read_csv('D:\\\\College_Football_Model_Data\\\\joinedDf.csv')\n",
    "\n",
    "##Display the first couple rows of the data to ensure its been pulled in \n",
    "joinedDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77eb66",
   "metadata": {},
   "source": [
    "Lets first examine the data types of the data to see which features might need cleaning to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e33599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10078 entries, 0 to 10077\n",
      "Data columns (total 40 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   gameId                      10078 non-null  int64  \n",
      " 1   week_num                    10078 non-null  int64  \n",
      " 2   school                      10078 non-null  object \n",
      " 3   rush_td                     10078 non-null  int64  \n",
      " 4   pass_td                     10078 non-null  int64  \n",
      " 5   rush_attempt                10078 non-null  int64  \n",
      " 6   yp_rush                     10078 non-null  float64\n",
      " 7   rush_yards                  10078 non-null  int64  \n",
      " 8   yp_pass                     10078 non-null  float64\n",
      " 9   completion_attempts         10078 non-null  object \n",
      " 10  pass_yards                  10078 non-null  int64  \n",
      " 11  total_yards                 10078 non-null  int64  \n",
      " 12  turnovers                   10078 non-null  int64  \n",
      " 13  tfl                         10078 non-null  float64\n",
      " 14  sacks                       10078 non-null  float64\n",
      " 15  qb_hurries                  10078 non-null  int64  \n",
      " 16  fumbles_lost                10078 non-null  int64  \n",
      " 17  interceptions               10078 non-null  int64  \n",
      " 18  possession_time             10078 non-null  object \n",
      " 19  penalty_yards               10078 non-null  object \n",
      " 20  fourthDown_eff              10078 non-null  object \n",
      " 21  thirdDown_eff               10078 non-null  object \n",
      " 22  firstDowns                  10078 non-null  int64  \n",
      " 23  defensive_td                10078 non-null  int64  \n",
      " 24  homeBool                    10078 non-null  int64  \n",
      " 25  gameSeason                  9387 non-null   float64\n",
      " 26  team_id                     9387 non-null   float64\n",
      " 27  points                      9387 non-null   float64\n",
      " 28  Quarterly_points            9387 non-null   object \n",
      " 29  elo                         8742 non-null   float64\n",
      " 30  offensive_plays             9934 non-null   float64\n",
      " 31  offensive_drives            9934 non-null   float64\n",
      " 32  offensive_ppa               9934 non-null   float64\n",
      " 33  offensive_successRate       9934 non-null   float64\n",
      " 34  offensive_explosiveness     9934 non-null   float64\n",
      " 35  offensive_powerSuccess      9934 non-null   float64\n",
      " 36  offensive_stuffRate         9934 non-null   float64\n",
      " 37  offensive_lineYards         9934 non-null   float64\n",
      " 38  offensive_secondLevelYards  9931 non-null   float64\n",
      " 39  offensive_openFieldYards    9687 non-null   float64\n",
      "dtypes: float64(18), int64(15), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "##Display the dataframe data types\n",
    "joinedDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4dd61d",
   "metadata": {},
   "source": [
    "From prior knowledge of this dataset, all the float64 and int64 data objects look correct as is. We can note some object data type columns that we must deal with in order to start cleaning the dataset. These are listed below:\n",
    "\n",
    "<b><i>Hyphenated Data:</i></b>\n",
    "* completion_attempts\n",
    "* penalty_yards\n",
    "* fourthDown_eff\n",
    "* thirdDown_eff\n",
    "\n",
    "<b><i>Time Data:</i></b>\n",
    "* possession_time\n",
    "\n",
    "<b><i>List Data:</i></b>\n",
    "* Quarterly_points\n",
    "\n",
    "In the section below we will perform transformations to better format the dataset to the columns listed above. \n",
    "\n",
    "### Hyphenated Data\n",
    "\n",
    "Below we will take a look at what is meant by \"hyphenated\" data. Essentially this is a datapoint where there is a \"-\" between two integers to indicates that a team has gone \"# for #\" in some statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db79614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completion_attempts</th>\n",
       "      <th>penalty_yards</th>\n",
       "      <th>fourthDown_eff</th>\n",
       "      <th>thirdDown_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31-38</td>\n",
       "      <td>1-10</td>\n",
       "      <td>2-2</td>\n",
       "      <td>10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15-29</td>\n",
       "      <td>1-9</td>\n",
       "      <td>2-3</td>\n",
       "      <td>1-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-25</td>\n",
       "      <td>10-92</td>\n",
       "      <td>0-0</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36-48</td>\n",
       "      <td>3-30</td>\n",
       "      <td>4-5</td>\n",
       "      <td>4-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8-23</td>\n",
       "      <td>4-50</td>\n",
       "      <td>0-0</td>\n",
       "      <td>2-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  completion_attempts penalty_yards fourthDown_eff thirdDown_eff\n",
       "0               31-38          1-10            2-2         10-15\n",
       "1               15-29           1-9            2-3          1-12\n",
       "2               20-25         10-92            0-0          5-10\n",
       "3               36-48          3-30            4-5          4-14\n",
       "4                8-23          4-50            0-0          2-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Display the hyphenated data columns\n",
    "joinedDf[['completion_attempts','penalty_yards','fourthDown_eff','thirdDown_eff']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4588a",
   "metadata": {},
   "source": [
    "One of the first things that needs to be addressed is if these data columns all have a \"-\" present, if not then the data may have an incorrect component to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3d1c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check all Data has \"-\":\n",
      "+---------------------+----------+\n",
      "| Column              | Status   |\n",
      "+=====================+==========+\n",
      "| completion_attempts | Correct  |\n",
      "+---------------------+----------+\n",
      "| penalty_yards       | Correct  |\n",
      "+---------------------+----------+\n",
      "| fourthDown_eff      | Correct  |\n",
      "+---------------------+----------+\n",
      "| thirdDown_eff       | Correct  |\n",
      "+---------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "##Display results of assessing if all data is hypenated\n",
    "hyph_colNames = ['completion_attempts','penalty_yards','fourthDown_eff','thirdDown_eff']\n",
    "hyph_data = [['Column','Status']]\n",
    "for i in hyph_colNames:\n",
    "    if len(joinedDf[joinedDf[i].str.contains('-')]) != len(joinedDf):\n",
    "        hyph_data.append([i,'Incorrect'])\n",
    "    else:\n",
    "        hyph_data.append([i,'Correct'])\n",
    "print('Check all Data has \"-\":')\n",
    "print(tabulate(hyph_data,headers='firstrow',tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3765e",
   "metadata": {},
   "source": [
    "The above results indicates that all data has a \"-\" present. This result generically indicates the data is a correct structure and we can move on to splitting the hyphenated data up. We now write a function to split hyphenated data into two new columns. \n",
    "\n",
    "Another thing that it would be important to check is if there is some error including a \"--\" double hyphen. This would indicate incorrect data and we'd want to explore places where this happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741642e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check no Data has \"--\":\n",
      "+---------------------+-----------+\n",
      "| Column              | Status    |\n",
      "+=====================+===========+\n",
      "| completion_attempts | Correct   |\n",
      "+---------------------+-----------+\n",
      "| penalty_yards       | Incorrect |\n",
      "+---------------------+-----------+\n",
      "| fourthDown_eff      | Correct   |\n",
      "+---------------------+-----------+\n",
      "| thirdDown_eff       | Correct   |\n",
      "+---------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "#joinedDf['penalty_yards'].loc[joinedDf['penalty_yards'].str.len() < 4].str.split('-')\n",
    "hyph_data = [['Column','Status']]\n",
    "for i in hyph_colNames:\n",
    "    if len(joinedDf[joinedDf[i].str.contains('--')]) > 0:\n",
    "        hyph_data.append([i,'Incorrect'])\n",
    "    else:\n",
    "        hyph_data.append([i,'Correct'])\n",
    "print('Check no Data has \"--\":')\n",
    "print(tabulate(hyph_data,headers='firstrow',tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42eae1",
   "metadata": {},
   "source": [
    "The above result shows that the penalty_yards column has a double \"--\" present, we will now explore the rows of data where this is happening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ceb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row of \"--\" Occurence:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>school</th>\n",
       "      <th>penalty_yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>401012776</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>7--4953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gameId         school penalty_yards\n",
       "6092  401012776  Arizona State       7--4953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game Record of \"--\" Occurence:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>school</th>\n",
       "      <th>penalty_yards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>401012776</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>7--4953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>401012776</td>\n",
       "      <td>USC</td>\n",
       "      <td>4-33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gameId         school penalty_yards\n",
       "6092  401012776  Arizona State       7--4953\n",
       "6093  401012776            USC          4-33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Filter data to location where double hypen is occuring\n",
    "print('Row of \"--\" Occurence:')\n",
    "display(joinedDf[joinedDf['penalty_yards'].str.contains('--')][['gameId','school','penalty_yards']])\n",
    "print('\\nGame Record of \"--\" Occurence:')\n",
    "gameId = (joinedDf.loc[joinedDf['penalty_yards'].str.contains('--'),'gameId'].tolist()[0])\n",
    "joinedDf[joinedDf['gameId']==gameId][['gameId','school','penalty_yards']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549e832",
   "metadata": {},
   "source": [
    "Above we see that only a single row is affected by this error, and the overall game corresponding to this error has a fine entry for penalty_yards for the other team. This data issue is a relatively simple fix, we will simply impute the value with the following:\n",
    "* New Value = $7-y\\cdot7$ where $y=$ average yards per penalty in the dataset. \n",
    "\n",
    "If this data error ever pops up in the future as well we will use the same data imputation technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcbab41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check all Data has \"--\":\n",
      "+---------------------+-------------+\n",
      "| Correct             | Incorrect   |\n",
      "+=====================+=============+\n",
      "| completion_attempts | Correct     |\n",
      "+---------------------+-------------+\n",
      "| penalty_yards       | Correct     |\n",
      "+---------------------+-------------+\n",
      "| fourthDown_eff      | Correct     |\n",
      "+---------------------+-------------+\n",
      "| thirdDown_eff       | Correct     |\n",
      "+---------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "##Define function that imputes average yards per penalty for corrupt penalty yards data\n",
    "####as documented above.\n",
    "def imputeAvg_penalty_yards(df,colName,error_delim='--',delim='-'):\n",
    "    \n",
    "    ##Filter dataframe to where the error is not\n",
    "    splitData = df[~df[colName].str.contains(error_delim)][colName].str.split(delim,expand=True)\n",
    "    numPenalties, numYards = np.array(splitData[0]).astype(float), np.array(splitData[1]).astype(float)\n",
    "    \n",
    "    ##Compute average yards per penalty\n",
    "    mean_ypp = 0\n",
    "    n = len(numPenalties)\n",
    "    for i,j in zip(numPenalties,numYards):\n",
    "        if i != 0 and j != 0:\n",
    "            mean_ypp = mean_ypp + (j/i)/n\n",
    "    \n",
    "    ##Define function for replacing error delimieter\n",
    "    def replace_delim(x,error_delim,delim,mean_ypp):\n",
    "        if error_delim in x:\n",
    "            x = x.replace(error_delim,delim)\n",
    "            delim_loc = x.find(delim)\n",
    "            x = x[:delim_loc+1] + str(int(int(x[:delim_loc])*mean_ypp))\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    ##Edit rows with incorrect data and impute average penalty yards\n",
    "    correctedData = df[colName].tolist()\n",
    "    for i in range(len(correctedData)):\n",
    "        correctedData[i] = replace_delim(correctedData[i],error_delim,delim,mean_ypp)\n",
    "    df[colName] = correctedData\n",
    "    \n",
    "    return df\n",
    "\n",
    "##Now lets fix the penalty_yards double-hyphenation issue and assess if it worked\n",
    "joinedDf = imputeAvg_penalty_yards(joinedDf,'penalty_yards')\n",
    "hyph_data = [['Correct','Incorrect']]\n",
    "for i in hyph_colNames:\n",
    "    if len(joinedDf[joinedDf[i].str.contains('--')]) > 0:\n",
    "        hyph_data.append([i,'Incorrect'])\n",
    "    else:\n",
    "        hyph_data.append([i,'Correct'])\n",
    "print('Check all Data has \"--\":')\n",
    "print(tabulate(hyph_data,headers='firstrow',tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223cbda0",
   "metadata": {},
   "source": [
    "The above result indicates that the issue with double-hypenation has been resolved. \n",
    "\n",
    "The next issue we must address is moving the hyphenation data into a form that can be better used for feature engineering and statistical modeling. To do this we will split each hyphenated column into two columns of integers. I have listed these splits below:\n",
    "* completion_attempts $\\rightarrow$ passAttempt, passComplete\n",
    "* penalty_yards $\\rightarrow$ penalties, penalty_yardage\n",
    "* fourthDown_eff $\\rightarrow$ fourthAttempts, fourthSuccess\n",
    "* thirdDown_eff $\\rightarrow$ thirdAttempts, thirdSuccess\n",
    "\n",
    "Below a function is defined to perform these splits and the new columns are added to the dataframe. We display these new columns below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9124fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define function to split hyphenated data into two new columns\n",
    "####NOTE: delimineter is default \"-\" but there is an option to change in for function generalizability\n",
    "def hyphenated_split(df,colName,newNames,delim='-'):\n",
    "    \n",
    "    ##Split by delimineter to create new columns and drop old column\n",
    "    df[newNames] = df[colName].str.split(delim, expand=True)\n",
    "    df = df.drop(colName,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "##Now for each of the hyphenated columns lets perform this transformation \n",
    "hyph_newNames = [['passAttempt','passComplete'],['penalties','penalty_yardage'],\n",
    "                 ['fourthAttempts','fourthSuccess'],['thirdAttempts','thirdSuccess']]\n",
    "for i in range(len(hyph_colNames)):\n",
    "    joinedDf = hyphenated_split(joinedDf,hyph_colNames[i],hyph_newNames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deb56b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passAttempt</th>\n",
       "      <th>passComplete</th>\n",
       "      <th>penalties</th>\n",
       "      <th>penalty_yardage</th>\n",
       "      <th>fourthAttempts</th>\n",
       "      <th>fourthSuccess</th>\n",
       "      <th>thirdAttempts</th>\n",
       "      <th>thirdSuccess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  passAttempt passComplete penalties penalty_yardage fourthAttempts  \\\n",
       "0          31           38         1              10              2   \n",
       "1          15           29         1               9              2   \n",
       "2          20           25        10              92              0   \n",
       "3          36           48         3              30              4   \n",
       "4           8           23         4              50              0   \n",
       "\n",
       "  fourthSuccess thirdAttempts thirdSuccess  \n",
       "0             2            10           15  \n",
       "1             3             1           12  \n",
       "2             0             5           10  \n",
       "3             5             4           14  \n",
       "4             0             2           14  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Display the new dataframe with split columns\n",
    "joinedDf[['passAttempt','passComplete','penalties','penalty_yardage',\n",
    "          'fourthAttempts','fourthSuccess','thirdAttempts','thirdSuccess']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb141f",
   "metadata": {},
   "source": [
    "We can see the split data resulting from the original hypenated columns is now in a much better form for future statistical modeling. The data is no longer string data so we'll be able to create new columns/features from this data to better evaluate game outcomes. \n",
    "\n",
    "### Time Data\n",
    "\n",
    "Now we must address the possession_time column. This data is given in the format of a mm:ss time count that indicates how long during a game the team had possession of the ball. \n",
    "\n",
    "Realistically speaking the we don't need any seconds data. This is because the minutes data is granular enough information for us to precisely model how long teams control the ball during a game. Therefore we'll perform the following data transformation:\n",
    "* possession_time $\\rightarrow$ possession_minutes\n",
    "\n",
    "Below we define a function to perform this data transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ee252b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37\n",
       "1    22\n",
       "2    29\n",
       "3    30\n",
       "4    20\n",
       "Name: possession_minutes, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Define function to replace possession time with integer value possession minutes\n",
    "def possession_minutes(df,colName):\n",
    "    \n",
    "    ##Create possession_minutes column and drop possession_time column\n",
    "    df['possession_minutes'] = df.apply(lambda row: row[colName][:row[colName].find(':')], axis = 1)\n",
    "    df = df.drop(colName,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "##Apply operation to dataframe and view results\n",
    "joinedDf = possession_minutes(joinedDf,'possession_time')\n",
    "joinedDf['possession_minutes'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d87c3b",
   "metadata": {},
   "source": [
    "### List Data\n",
    "\n",
    "The only list data we have comes from the Quarterly_points column. Each row in this column contains a list with 4 elements, for example [7,14,0,3]. The element of the list are the points scored per quarter, out of all 4 quarters. We will perform the following transformation:\n",
    "* Quarterly_points $\\rightarrow$ Q1_points, Q2_points, Q3_points, Q4_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d55e002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define function to split quarterly points in gameDf into separate columns\n",
    "from ast import literal_eval\n",
    "def split_quarterly_pts(df):\n",
    "    \n",
    "    df['Quarterly_points1'] = df.apply(lambda row: [] if str(row['Quarterly_points']) == 'nan' else\n",
    "                                               literal_eval(str(row['Quarterly_points'])),axis=1)\n",
    "    df['quarters_available'] = df.apply(lambda row: len(row['Quarterly_points1']), axis = 1)\n",
    "\n",
    "    for i,j in zip(['Q1_points','Q2_points','Q3_points','Q4_points'],[0,1,2,3]):\n",
    "        df[i] = df.apply(lambda row: row['Quarterly_points1'][j] if len(row['Quarterly_points1'])>0 else 0, axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e16291a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-8c312960760a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_quarterly_pts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoinedDf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-03a1a19f8499>\u001b[0m in \u001b[0;36msplit_quarterly_pts\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q1_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q2_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q3_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q4_points'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quarterly_points1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quarterly_points1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-03a1a19f8499>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q1_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q2_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q3_points'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Q4_points'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quarterly_points1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quarterly_points1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df = split_quarterly_pts(joinedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bfc40ccf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-42fe3c33a085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Quarterly_points'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "df[len(df['Quarterly_points'])==11].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7aca56fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarterly_points</th>\n",
       "      <th>gameSeason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>[14, 0, 0, 17, 7, 7, 0, 8, 6, 6, 3]</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>[10, 7, 7, 7, 7, 7, 0, 8, 6, 6, 6]</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>[7, 10, 7, 7, 3, 7, 8, 3, 6, 8, 8]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>[7, 3, 7, 14, 3, 7, 8, 3, 6, 8, 6]</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Quarterly_points  gameSeason\n",
       "4034  [14, 0, 0, 17, 7, 7, 0, 8, 6, 6, 3]      2017.0\n",
       "4035   [10, 7, 7, 7, 7, 7, 0, 8, 6, 6, 6]      2017.0\n",
       "6540   [7, 10, 7, 7, 3, 7, 8, 3, 6, 8, 8]      2018.0\n",
       "6541   [7, 3, 7, 14, 3, 7, 8, 3, 6, 8, 6]      2018.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####These are indicative of overtime games\n",
    "df.loc[df['quarters_available']==11,['Quarterly_points','gameSeason']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
